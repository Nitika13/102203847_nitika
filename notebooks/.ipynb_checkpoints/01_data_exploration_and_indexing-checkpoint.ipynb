{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9f5a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install notebook pandas numpy matplotlib scikit-learn sentence-transformers faiss-cpu pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfc5bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 01 â€” Data exploration & embedding index\n",
    "#Load dataset, run EDA, compute text embeddings using `all-MiniLM-L6-v2` and save embeddings + index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86e179",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41115fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\"..\",\"backend\",\"data\",\"products.csv\")\n",
    "# if running inside backend folder use: DATA_PATH = \"data/products.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head(), df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b5557",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fill missing values and create a combined text field for embedding\n",
    "df['title'] = df['title'].fillna(\"\").astype(str)\n",
    "df['description'] = df['description'].fillna(\"\").astype(str)\n",
    "df['categories'] = df.get('categories', pd.Series([\"\"]*len(df))).fillna(\"\").astype(str)\n",
    "df['text'] = (df['title'] + \". \" + df['description'] + \". \" + df['categories']).str.strip()\n",
    "# add a string id column\n",
    "if 'uniq_id' not in df.columns:\n",
    "    df['uniq_id'] = df.index.astype(str)\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"Rows:\", len(df))\n",
    "df[['uniq_id','title','text']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edfc012",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Category counts\n",
    "print(\"Category counts:\")\n",
    "print(df['categories'].value_counts().head(10))\n",
    "\n",
    "# Price stats (if price exists)\n",
    "if 'price' in df.columns:\n",
    "    print(\"\\nPrice stats:\")\n",
    "    print(df['price'].describe())\n",
    "\n",
    "# Show 5 random examples\n",
    "df.sample(5)[['uniq_id','title','categories','price']].transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e04e14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot category distribution (top 10)\n",
    "top = df['categories'].value_counts().head(10)\n",
    "plt.figure(figsize=(8,4))\n",
    "top.plot.bar()\n",
    "plt.title(\"Top 10 categories\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a468d03",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # small & fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c258d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# compute embeddings in batches to avoid memory spikes\n",
    "texts = df['text'].tolist()\n",
    "BATCH = 64\n",
    "embs = []\n",
    "for i in range(0, len(texts), BATCH):\n",
    "    batch = texts[i:i+BATCH]\n",
    "    e = model.encode(batch, show_progress_bar=False, convert_to_numpy=True)\n",
    "    embs.append(e)\n",
    "embeddings = np.vstack(embs)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "# normalize (for cosine)\n",
    "embeddings = normalize(embeddings, norm='l2', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69f596",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "OUT_DIR = os.path.join(\"..\",\"backend\",\"models\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "np.save(os.path.join(OUT_DIR, \"embeddings.npy\"), embeddings)\n",
    "df.to_csv(os.path.join(OUT_DIR, \"products_with_text.csv\"), index=False)\n",
    "print(\"Saved embeddings to\", os.path.join(OUT_DIR,\"embeddings.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed30c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import faiss\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)  # inner-product on normalized vectors = cosine\n",
    "    index.add(embeddings.astype('float32'))\n",
    "    # save index\n",
    "    faiss.write_index(index, os.path.join(OUT_DIR, \"faiss_index.idx\"))\n",
    "    print(\"Built and saved FAISS index.\")\n",
    "except Exception as e:\n",
    "    print(\"FAISS not available or error:\", e)\n",
    "    # fallback: save embeddings + use sklearn.NearestNeighbors later\n",
    "    joblib.dump({\"embeddings\": embeddings, \"ids\": df['uniq_id'].tolist()}, os.path.join(OUT_DIR, \"nn_store.pkl\"))\n",
    "    print(\"Saved embeddings for sklearn fallback.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada793a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Query example: use first row text\n",
    "query_text = df.loc[0, 'text']\n",
    "q_emb = model.encode([query_text], convert_to_numpy=True)\n",
    "q_emb = q_emb / np.linalg.norm(q_emb, axis=1, keepdims=True)\n",
    "k = min(6, len(df))\n",
    "try:\n",
    "    # faiss path\n",
    "    D, I = index.search(q_emb.astype('float32'), k)\n",
    "    print(\"Top ids:\", df.loc[I[0], ['uniq_id','title']])\n",
    "except:\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    store = joblib.load(os.path.join(OUT_DIR,\"nn_store.pkl\"))\n",
    "    neigh = NearestNeighbors(n_neighbors=k, metric='cosine').fit(store['embeddings'])\n",
    "    dist, idx = neigh.kneighbors(q_emb)\n",
    "    print(df.iloc[idx[0]][['uniq_id','title']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f06b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Summary\n",
    "- Embeddings saved: `backend/models/embeddings.npy`\n",
    "- Index saved: `backend/models/faiss_index.idx` or `backend/models/nn_store.pkl`\n",
    "- Next: open `02_model_training_and_evaluation.ipynb` to evaluate retrieval and run small ML experiments.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
